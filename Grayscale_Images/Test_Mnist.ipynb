{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Matrix Operations\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# For TDA\n",
    "import gudhi\n",
    "import gudhi.wasserstein\n",
    "import gudhi.hera\n",
    "import ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence(array, dimension=None):\n",
    "  height, width = array.shape\n",
    "  cubeComplex = gudhi.CubicalComplex(\n",
    "      dimensions = [width,height],\n",
    "      top_dimensional_cells = 255 - array.flatten()\n",
    "  )\n",
    " \n",
    "  if dimension == None:\n",
    "    persistence = cubeComplex.persistence()\n",
    "  else:\n",
    "    cubeComplex.compute_persistence()\n",
    "    persistence = cubeComplex.persistence_intervals_in_dimension(dimension)\n",
    "    \n",
    "  return persistence\n",
    "def Get_Vinyard(f, g, D, t = 101):\n",
    "##########\n",
    "    # input:\n",
    "        # f and g by which you want to interpolate using straight line homotopy\n",
    "        # the dimension of persistence you want\n",
    "    # output:\n",
    "        # series of persistence diagrams: hs\n",
    "        # persistence vinyard polotted in 3d space: res\n",
    "        # death value of largest persistence: mx\n",
    "\n",
    "##########\n",
    "\n",
    "\n",
    "    # creates equal intervals from 0 to 100\n",
    "    ts = np.linspace(0,1,t)\n",
    "    # creates homology from f to g using these intervals\n",
    "    hs = np.array([(t * f) + (1-t) * g for t in ts])\n",
    "    \n",
    "    PDD = [persistence(h,dimension = D) for h in hs]\n",
    "\n",
    "# tracking each vine. the third entry tracks what vine is matche dup to what wasserstein point\n",
    "    # vines[0] is birth frame\n",
    "    # vines[1] is death frame\n",
    "    # vines[2] keeps track of what point the vine is in the corresponding persistence diagram\n",
    "    vines = [[0, None, [x,]] for x in range(len(PDD[0]))]\n",
    "    # each vine is matched to itself in the ends matrix\n",
    "    ends = {x:x for x in range(len(PDD[0]))}\n",
    "\n",
    "    for i in range(1, len(ts)):\n",
    "        dist, match = gudhi.hera.wasserstein_distance(PDD[i-1], PDD[i], matching = True)\n",
    "\n",
    "        baby = [] \n",
    "\n",
    "        new_ends = {k:ends[k] for k in ends}\n",
    "        for j, (x,y) in enumerate(match):\n",
    "            if x == -1:\n",
    "                baby.append(j)\n",
    "            elif y == -1:\n",
    "                # ends the vine\n",
    "                \n",
    "                # we record death frame\n",
    "                vines[ends[x]][1] = i\n",
    "                # -1 tells us the vine is dead in our PD\n",
    "                vines[ends[x]][2].append(-1)\n",
    "            else:\n",
    "                # updating vines. Adding the match to our vines matrix\n",
    "                vines[ends[x]][2].append(y)\n",
    "                # setting ends to new_ends for the next iteration\n",
    "                new_ends[y] = ends[x] \n",
    "\n",
    "        for j in baby:\n",
    "            x, y = match[j]\n",
    "            new_ends[y] = len(vines)\n",
    "            vines.append([i, None, [y,]])\n",
    "            # print(f\"new {y} -> *\")\n",
    "\n",
    "        for k in [l for l in ends]: \n",
    "            if k >= len(PDD[i]):\n",
    "                del new_ends[k]\n",
    "\n",
    "        ends = new_ends\n",
    "\n",
    "\n",
    "    # this block takes the tracking in vines[i][2] and replaces it with the numpy array of the vines birth and death times.\n",
    "    # these times are taken at each time step of our vinyard\n",
    "    # for example: poss[1][2][3] is the birth/death times of vine number 2 at time step 4. Note that indices are 1 less than their frame #\n",
    "    poss = vines\n",
    "    for i,_ in enumerate(vines):\n",
    "        repl = []\n",
    "        for j,x in enumerate(vines[i][2]):\n",
    "            # if vine is dead at that frame\n",
    "            if x == -1:\n",
    "                repl.append(np.mean(PDD[vines[i][0]+j-1][vines[i][2][j-1]])*np.ones((2,))) # proj prev\n",
    "            else:\n",
    "                repl.append(PDD[vines[i][0]+j][x])\n",
    "        poss[i][2] = np.array(repl)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # these are the vine values in 3d space\n",
    "\n",
    "    # we iterate through each vine, to create a res entry (res[0] corresponds to vine zero)\n",
    "    # res[0][b(t) -> d(t)] is a triple list consisting of:\n",
    "        # [time value, birth time, death time]\n",
    "\n",
    "    res = [[[ts[p[0]+np.arange(len(p[2]))][i], *x] for i,x in enumerate(p[2])] for p in poss]\n",
    "\n",
    "    mx = 'hey'\n",
    "    #mx = np.max([np.max(p[2]) for p in poss if np.inf not in p[2]])\n",
    "    # getting the max death time of all the vines\n",
    "\n",
    "    return res, mx, hs\n",
    "def Plot_Vinyard(res, mx, hs):\n",
    "\n",
    "\n",
    "    gos = []\n",
    "\n",
    "    # x axis is time\n",
    "    # y axis is birth time\n",
    "    # z axis is death time\n",
    "    for vine in res:\n",
    "        vine = np.array(vine)\n",
    "\n",
    "        gos.append(go.Scatter3d(x=vine[:,0], y=vine[:,1], z=vine[:,2], marker=dict(\n",
    "            size=2,\n",
    "        ),\n",
    "        line=dict(\n",
    "            width=2\n",
    "        )))\n",
    "\n",
    "\n",
    "    xs = np.linspace(0, mx, 10)\n",
    "    zs = np.linspace(0, 1, 10)\n",
    "    xss, zss = np.meshgrid(xs, zs)\n",
    "    gos.append(go.Surface(x=zss, y=xss, z=xss, colorscale=[[0, '#333'], [1, '#333']], opacity=0.1, showscale=False)) # x - y = 0: diag plane\n",
    "    fig = go.Figure(data=gos)\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        height=700,\n",
    "        scene=dict(\n",
    "        xaxis_title='T (homotopy)',\n",
    "        yaxis_title='Birth',\n",
    "        zaxis_title='Death'\n",
    "    )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "def vdist(res, f, g): # diag weight func, length weight func\n",
    "    V = 0\n",
    "    for vine in res:\n",
    "        vine = np.array(vine)\n",
    "        v, L = 0, 0\n",
    "        for i in range(1, len(vine)):\n",
    "            l = np.linalg.norm(vine[i][1:]-vine[i-1][1:])\n",
    "            dt = vine[i][0] - vine[i-1][0]\n",
    "\n",
    "            mid = np.mean([vine[i][1:],vine[i-1][1:]], axis=0)\n",
    "            proj = np.mean(mid)*np.ones(2,)\n",
    "            # this is the persistence of the mid point distance traveled\n",
    "            D = np.linalg.norm(proj-mid)\n",
    "            \n",
    "            v += f(D)*l*dt\n",
    "            L += l*dt\n",
    "\n",
    "        v *= g(L)\n",
    "        V += v\n",
    "\n",
    "    return V\n",
    "def fD(D):\n",
    "    return D/100\n",
    "def fL(L):\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Mnist(N1, N2, dimension = 1, no_samples = 100):\n",
    "\n",
    "    # fetching Mnist, finding a three and a eight. Creating an f and g for our test:\n",
    "\n",
    "    X, y = fetch_openml('Mnist_784', version = 1, return_X_y = True, as_frame = False)\n",
    "    # X is 70000 images, y is the classifications\n",
    "    X.shape\n",
    "    # taking each image and turning it into a 3d array. Each slide is a 28 by 28 grayscale grid\n",
    "\n",
    "    X = X.reshape(X.shape[0],28,28)\n",
    "\n",
    "    # finding all the 6's and 9's and filtering them out\n",
    "    f = X[np.where(y == str(N1))]\n",
    "    g = X[np.where(y == str(N2))]\n",
    "\n",
    "\n",
    "    if no_samples > len(f) or no_samples >len(g):\n",
    "        no_samples = max(len(f), len(g))\n",
    "    f = f[:no_samples]\n",
    "    g = g[:no_samples]\n",
    "\n",
    "    Combined_Array = np.concatenate((f, g), axis = 0)\n",
    "\n",
    "    # Distances Calculations\n",
    "    Vinyard_Distances = np.zeros((Combined_Array.shape[0], Combined_Array.shape[0]))\n",
    "\n",
    "    for i in range(Combined_Array.shape[0]):\n",
    "        for j in range(i+1,Combined_Array.shape[0]):\n",
    "            Vinyard_Distances[i,j] = vdist(Get_Vinyard(Combined_Array[i], Combined_Array[j],dimension, t = 100)[0],fD,fL)\n",
    "    Vinyard_Distances += np.transpose(Vinyard_Distances)\n",
    "\n",
    "    # MDS Embedding\n",
    "    Vinyard_MDS_Embedding = MDS(n_components = 2, metric = True, dissimilarity = 'precomputed', random_state = 32).fit_transform(Vinyard_Distances)\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Red is N1 and Blue is N2\n",
    "    scatter = ax.scatter(Vinyard_MDS_Embedding[:, 0], Vinyard_MDS_Embedding[:, 1], c = ['red'] * no_samples + ['blue'] * no_samples, s=10)\n",
    "\n",
    "\n",
    "    plt.title('Vinyard MDS')\n",
    "    plt.xlabel('MDS Component 1')\n",
    "    plt.ylabel('MDS Component 2')\n",
    "    plt.show()\n",
    "    return Vinyard_Distances\n",
    "Test_Mnist(6,9, dimension = 1, no_samples = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "See [Turner and Robinson Paper](https://arxiv.org/pdf/1310.7467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing between 6 and 9\n",
    "N1 = 6\n",
    "N2 = 9\n",
    "\n",
    "# 100 samples of 6's and 9's are drawn each\n",
    "no_samples = 100\n",
    "# In robinson and turner, they take 10 samples from each group and compute the loss function.\n",
    "\n",
    "def loss_function(PDS, metric = 'wasserstein'):\n",
    "    if metric == 'wasserstein':\n",
    "        n = len(PDS)\n",
    "        loss = 0\n",
    "        for i, PD1 in enumerate(PDS): \n",
    "            for j, PD2 in enumerate(PDS):\n",
    "                if i <= j:\n",
    "                    loss += (gudhi.hera.wasserstein_distance(PD1, PD2))\n",
    "        \n",
    "        loss *= (1/(2 * n*(n-1)))\n",
    "        return loss\n",
    "\n",
    "    elif metric == 'vinyard':\n",
    "            pass\n",
    "\n",
    "    return 'blruh'\n",
    "\n",
    "\n",
    "# fetching Mnist, finding a three and a eight. Creating an f and g for our test:\n",
    "\n",
    "X, y = fetch_openml('Mnist_784', version = 1, return_X_y = True, as_frame = False)\n",
    "# X is 70000 images, y is the classifications\n",
    "X.shape\n",
    "# taking each image and turning it into a 3d array. Each slide is a 28 by 28 grayscale grid\n",
    "\n",
    "X = X.reshape(X.shape[0],28,28)\n",
    "\n",
    "# finding all the 6's and 9's and filtering them out\n",
    "f = X[np.where(y == str(N1))]\n",
    "g = X[np.where(y == str(N2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_matrix(PDS):\n",
    "    lm = np.zeros((len(PDS), len(PDS)))\n",
    "    for i in range(len(PDS)):\n",
    "        for j in range(len(PDS)):\n",
    "            if i < j:\n",
    "                lm[i][j] = gudhi.hera.wasserstein_distance(PDS[i], PDS[j])\n",
    "    lm += np.transpose(lm)\n",
    "\n",
    "    return lm\n",
    "np.random.seed(123456789)\n",
    "# sourcing images\n",
    "f = X[np.where(y == str(N1))]\n",
    "g = X[np.where(y == str(N2))]\n",
    "# setting persistence dimension and length of our straight line homotopy\n",
    "D = 1\n",
    "t = 10\n",
    "\n",
    "# at each time step k, this is the amount of images we pull out of f or g\n",
    "p = 10\n",
    "# for each set of 10 images, this is the number of permutations we go through\n",
    "N = 10000\n",
    "# list that will store all of our Z values\n",
    "ZsW = []\n",
    "\n",
    "for i in range(100):\n",
    "    f_test = f[i* 10 :10*(i+1)]\n",
    "    g_test = g[i * 10:10*(i+1)]\n",
    "\n",
    "    # Generating PDS\n",
    "    PDS1 = [persistence(six,1) for six in f_test]\n",
    "    PDS2 = [persistence(nine,1) for nine in g_test]\n",
    "    PDS_Combined = PDS1 + PDS2\n",
    "\n",
    "\n",
    "    # getting observed loss and loss matrix\n",
    "    loss_observed = 0\n",
    "    lm = loss_matrix(PDS_Combined)\n",
    "    label1 = [x for x in range(10)]\n",
    "    label2 = [10 + x for x in range(10)]\n",
    "\n",
    "    for i, _ in enumerate(label1):\n",
    "        for j, _ in enumerate(label1):\n",
    "            if i<= j:\n",
    "                loss_observed += lm[label1[i]][label1[j]]\n",
    "                loss_observed += lm[label2[i]][label2[j]]\n",
    "    #loss_observed *= (1/(2 * p*(p-1)))\n",
    "\n",
    "    #calculating observed loss and initializing Z\n",
    "    \n",
    "    Z = 0\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        # Shuffling the labels\n",
    "        rand_perm = np.random.permutation(len(PDS_Combined))\n",
    "        label1 = rand_perm[:10]\n",
    "        label2 = rand_perm[10:]\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # computing the loss functions again\n",
    "        for i, _ in enumerate(label1):\n",
    "            for j, _ in enumerate(label1):\n",
    "                if i<= j:\n",
    "                    loss += lm[label1[i]][label1[j]]\n",
    "                    loss += lm[label2[i]][label2[j]]\n",
    "        #loss *= (1/(2 * p*(p-1)))\n",
    "        # if loss <= observed loss: Z += 1\n",
    "        if loss <= loss_observed:\n",
    "            Z += 1\n",
    "    Z /= (N+1)\n",
    "    ZsW.append(Z)\n",
    "ZsW = np.array(ZsW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m             Z \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     71\u001b[0m     Z \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (N\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mZsW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(Z)\n\u001b[1;32m     73\u001b[0m ZsW2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ZsW)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "def loss_matrix(PDS):\n",
    "    lm = np.zeros((len(PDS), len(PDS)))\n",
    "    for i in range(len(PDS)):\n",
    "        for j in range(len(PDS)):\n",
    "            if i < j:\n",
    "                lm[i][j] = gudhi.hera.wasserstein_distance(PDS[i], PDS[j])\n",
    "    lm += np.transpose(lm)\n",
    "\n",
    "    return lm\n",
    "np.random.seed(123456789)\n",
    "# sourcing images\n",
    "f = X[np.where(y == str(N1))]\n",
    "g = X[np.where(y == str(N2))]\n",
    "# setting persistence dimension and length of our straight line homotopy\n",
    "D = 1\n",
    "t = 10\n",
    "\n",
    "# at each time step k, this is the amount of images we pull out of f or g\n",
    "p = 10\n",
    "# for each set of 10 images, this is the number of permutations we go through\n",
    "N = 10000\n",
    "# list that will store all of our Z values\n",
    "ZsW2 = []\n",
    "\n",
    "for i in range(100):\n",
    "    f_test = f[i* 10 :10*(i+1)]\n",
    "    g_test = g[i * 10:10*(i+1)]\n",
    "\n",
    "    # Generating PDS\n",
    "    PDS1 = [persistence(six,1) for six in f_test]\n",
    "    PDS2 = [persistence(nine,1) for nine in g_test]\n",
    "    PDS_Combined = PDS1 + PDS2\n",
    "\n",
    "\n",
    "    # getting observed loss and loss matrix\n",
    "    loss_observed = 0\n",
    "    lm = loss_matrix(PDS_Combined)\n",
    "    label1 = [x for x in range(10)]\n",
    "    label2 = [10 + x for x in range(10)]\n",
    "\n",
    "    for i, _ in enumerate(label1):\n",
    "        for j, _ in enumerate(label1):\n",
    "            #if i<= j:\n",
    "            loss_observed += lm[label1[i]][label1[j]]\n",
    "            loss_observed += lm[label2[i]][label2[j]]\n",
    "    loss_observed *= (1/(2 * p*(p-1)))\n",
    "\n",
    "    #calculating observed loss and initializing Z\n",
    "    \n",
    "    Z = 0\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        # Shuffling the labels\n",
    "        rand_perm = np.random.permutation(len(PDS_Combined))\n",
    "        label1 = rand_perm[:10]\n",
    "        label2 = rand_perm[10:]\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # computing the loss functions again\n",
    "        for i, _ in enumerate(label1):\n",
    "            for j, _ in enumerate(label1):\n",
    "                #if i<= j:\n",
    "                loss += lm[label1[i]][label1[j]]\n",
    "                loss += lm[label2[i]][label2[j]]\n",
    "        loss *= (1/(2 * p*(p-1)))\n",
    "        # if loss <= observed loss: Z += 1\n",
    "        if loss <= loss_observed:\n",
    "            Z += 1\n",
    "    Z /= (N+1)\n",
    "    ZsW.append(Z)\n",
    "ZsW2 = np.array(ZsW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ZsW)\n",
    "print(ZsW2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting random seed\n",
    "np.random.seed(123456789)\n",
    "# sourcing images\n",
    "f = X[np.where(y == str(N1))]\n",
    "g = X[np.where(y == str(N2))]\n",
    "# setting persistence dimension and length of our straight line homotopy\n",
    "D = 1\n",
    "t = 10\n",
    "\n",
    "# at each time step k, this is the amount of images we pull out of f or g\n",
    "p = 10\n",
    "# for each set of 10 images, this is the number of permutations we go through\n",
    "N = 10000\n",
    "# list that will store all of our Z values\n",
    "ZsV = []\n",
    "\n",
    "# initializing loss observed and \n",
    "# we are taking 10 6's and 10 9's and repeating the loss function 100 times. This will give us 100 Z's to work with\n",
    "for k in range(100):\n",
    "\n",
    "    f_test = f[k * p : p * (k + 1)]\n",
    "    g_test = g[k * p : p * (k + 1)]\n",
    "\n",
    "    loss_observed = 0\n",
    "    Z = 0\n",
    "\n",
    "\n",
    "    # arrays\n",
    "    Combined_Array = np.concatenate((f_test, g_test), axis = 0)\n",
    "\n",
    "    Vin_Cost_Array = np.zeros((len(Combined_Array), len(Combined_Array)))\n",
    "\n",
    "    # computing cost array\n",
    "    for i in range(Vin_Cost_Array.shape[0]):\n",
    "        for j in range(Vin_Cost_Array.shape[0]):\n",
    "            if i < j:\n",
    "                Vin_Cost_Array[i][j] = vdist(Get_Vinyard(Combined_Array[i], Combined_Array[j], D = 1 ,t= 11)[0], fD, fL)\n",
    "    Vin_Cost_Array += np.transpose(Vin_Cost_Array)\n",
    "\n",
    "    # getting the observed loss functions\n",
    "\n",
    "    # standard labels [1, 2, ..., 10] and [11, 12, ..., 19]\n",
    "\n",
    "    label1 = [x for x in range(10)]\n",
    "    label2 = [10 + x for x in range(10)]\n",
    "\n",
    "\n",
    "    for i, _ in enumerate(label1):\n",
    "        for j, _ in enumerate(label1):\n",
    "            if i<= j:\n",
    "                loss_observed += Vin_Cost_Array[label1[i]][label1[j]]\n",
    "                loss_observed += Vin_Cost_Array[label2[i]][label2[j]]\n",
    "    loss_observed *= (1/(2 * p*(p-1)))\n",
    "\n",
    "\n",
    "    for n in range(N):\n",
    "\n",
    "        rand_perm = np.random.permutation(len(Combined_Array))\n",
    "        label1 = rand_perm[:10]\n",
    "        label2 = rand_perm[10:]\n",
    "        loss = 0\n",
    "        for i, _ in enumerate(label1):\n",
    "            for j, _ in enumerate(label1):\n",
    "                if i<= j:\n",
    "                    loss += Vin_Cost_Array[label1[i]][label1[j]]\n",
    "                    loss += Vin_Cost_Array[label2[i]][label2[j]]\n",
    "        loss *= (1/(2 * p*(p-1)))\n",
    "    \n",
    "        if loss <= loss_observed:\n",
    "            Z += 1\n",
    "\n",
    "    Z /= (N+1)\n",
    "    ZsV.append(Z)\n",
    "ZsV = np.array(ZsV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'wasserstein: {ZsW}')\n",
    "print(f'vineyard: {ZsV}')\n",
    "ZsW = np.array(ZsW)\n",
    "ZsV = np.array(ZsV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.005, 0.01, 0.015, 0.02, 0.025]\n",
    "yvals = [np.sum(ZsW <=a) for a in alpha]\n",
    "plt.plot(alpha,yvals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
